{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389621ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyle\\AppData\\Local\\Temp\\ipykernel_43660\\1046658704.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mevaluation\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mload_data\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPadgan_variants\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# import GANs\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'load_data'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import random\n",
    "\n",
    "import importlib\n",
    "import evaluation\n",
    "import load_data\n",
    "import Padgan_variants\n",
    "# import GANs\n",
    "import VAEs\n",
    "\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(load_data)\n",
    "# importlib.reload(GANs)\n",
    "importlib.reload(VAEs)\n",
    "importlib.reload(Padgan_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_generate(functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status):\n",
    "    \n",
    "    \n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    #Initialize np array to hold generated samples\n",
    "    generated = np.zeros((len(functions), len(methods), numinst, numgen, 2))\n",
    "\n",
    "    #Loop over number of model instantiations to test\n",
    "    for inst in range(numinst):\n",
    "        #Loop over the problems to test\n",
    "        for func in range(len(functions)):\n",
    "            #Unpack various problem parameters\n",
    "            samplingfunction, validityfunction, objectives, rangearr, cond_func, cond = functions[func]\n",
    "            \n",
    "            #Generate the data\n",
    "            valid_scaled, invalid_scaled, scaler = load_data.gen_toy_dataset(samplingfunction, validityfunction, objectives, rangearr, scaling)\n",
    "            \n",
    "            #Get some unscaled versions of the data to use for calculating objectives/condition parameters\n",
    "            if scaling: \n",
    "                valid = scaler.inverse_transform(valid_scaled)\n",
    "            else:\n",
    "                valid = valid_scaled\n",
    "                \n",
    "            #Evaluate objective values for all datapoints\n",
    "            if obj_status:\n",
    "                y_valid = load_data.eval_obj(valid, objectives)\n",
    "            else:\n",
    "                y_valid = None\n",
    "            \n",
    "            #Evaluate condition value for all datapoints\n",
    "            if conditional_status:\n",
    "                c_valid = load_data.eval_obj(valid, [cond_func])\n",
    "            else:\n",
    "                c_valid = None\n",
    "            #Loop over DGMs\n",
    "            for i in range(len(methods)): \n",
    "                method = methods.values[i]\n",
    "                \n",
    "                #Get trained model\n",
    "                model = method(valid_scaled, invalid_scaled, y_valid, c_valid)\n",
    "                \n",
    "                #Call generate function (models are assumed to have a class function, generate)\n",
    "                x_fake_scaled = model.generate(numgen, np.full(numgen, cond))\n",
    "                \n",
    "                #Add to generated results array\n",
    "                x_fake_scaled = np.array(x_fake_scaled)\n",
    "                generated[func, i, inst, :, :] = x_fake_scaled\n",
    "\n",
    "    #Save and return results\n",
    "    np.save(f\"Scores/Generated_samples_{timestr}.npy\", generated)\n",
    "    return generated, timestr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(ax, rangearr, xx, yy, Z, x, y, x2,y2, title, boundary=0.0, colors=[\"#FC766A\", \"#5B84B1\"], plottype = \"generated\", validity_status=0, target=None):\n",
    "    \n",
    "    font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 30}\n",
    "    plt.rc('font', **font)\n",
    "    \n",
    "    vdatacol=\"#000000\"\n",
    "    blue = \"#6C8EBF\"\n",
    "    orange = \"#F2AF00\"\n",
    "    yellow = \"#D6B656\"\n",
    "    white = \"#FFFFFF\"\n",
    "    purple = \"#9673A6\"\n",
    "    vgencol = orange\n",
    "    \n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"#FFFFFF\",\"#6C8EBF\"], N=7)\n",
    "    objcmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [white , orange], N=6)\n",
    "    \n",
    "    s=6\n",
    "    ax.set_title(title)\n",
    "    if validity_status==1: #Invalid Samples\n",
    "        if plottype == \"dataset\":\n",
    "            ax.contourf(xx, yy, Z, cmap=cmap, alpha=0.1)\n",
    "            ax.scatter(x,y, s=s, c=[\"#6C8EBF\"], alpha=0.5)\n",
    "        elif plottype == \"invalid\":\n",
    "            ax.contourf(xx, yy, Z, cmap=cmap, alpha=0.1)\n",
    "            ax.scatter(x,y, s=s, c=[\"#000000\"], alpha=0.2)\n",
    "        elif plottype == \"generated\":\n",
    "            ax.contourf(xx, yy, Z, cmap=cmap, alpha=0.1)\n",
    "            ax.scatter(x,y, s=s, c=[\"#6C8EBF\"])\n",
    "            ax.scatter(x2,y2, s=s, c=[\"#000000\"])\n",
    "        elif plottype == \"objective\":\n",
    "            img = ax.imshow(Z.T, cmap=objcmap, alpha=0.7, origin='lower', extent = [-2,2,-2,2])    \n",
    "            plt.colorbar(img, ax=ax, fraction=0.046, pad=0.04)\n",
    "            ax.scatter(x,y, s=s, c=\"k\", alpha = 0.3)\n",
    "            if target:\n",
    "                CS = ax.contour(Z.T, [target], colors='k', vmin=0, vmax=2, extent = [-2,2,-2,2])\n",
    "                ax.clabel(CS, fontsize=30, inline=True)\n",
    "#                 manual_locations = [(-2, 2), (2,-2)]\n",
    "#                 ax.clabel(CS, fontsize=30, inline=True, manual=manual_locations)\n",
    "    else:\n",
    "        if plottype==\"objective\":\n",
    "            img = ax.imshow(Z.T, cmap=objcmap, alpha=0.5, origin='lower', extent = [-2,2,-2,2])\n",
    "            plt.colorbar(img, ax=ax, fraction=0.046, pad=0.04)\n",
    "            ax.scatter(x,y, s=s, c=\"k\", alpha = 0.3)\n",
    "            if target:\n",
    "                CS = ax.contour(Z.T, [target], colors='k', vmin=0, vmax=2, extent = [-2,2,-2,2])\n",
    "                ax.clabel(CS, fontsize=30, inline=True)\n",
    "#                 manual_locations = [(-2, 2), (2,-2)]\n",
    "#                 ax.clabel(CS, fontsize=30, inline=True, manual=manual_locations)\n",
    "            \n",
    "        elif plottype==\"dataset\": #No invalid Samples\n",
    "            ax.scatter(x,y, s=s, c=vdatacol, alpha=0.15)\n",
    "            ax.set_title(\"Original Data\")\n",
    "        elif plottype==\"generated\":\n",
    "            ax.scatter(x2,y2, s=s, c=vdatacol, alpha=0.05)\n",
    "            ax.scatter(x,y, s=s, c=vgencol, alpha=0.7)\n",
    "        elif plottype==\"conditional\":\n",
    "            ax.scatter(x2,y2, s=s, c=vdatacol, alpha=0.1)\n",
    "            ax.scatter(x,y, s=s, c=vgencol, alpha=0.7)\n",
    "    xlen = rangearr[0,1]-rangearr[0,0]\n",
    "    ylen = rangearr[1,1]-rangearr[1,0]\n",
    "    ax.set_xlim(rangearr[0,0]-xlen*boundary, rangearr[0,1]+xlen*boundary)\n",
    "    ax.set_ylim(rangearr[1,0]-ylen*boundary, rangearr[1,1]+ylen*boundary)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428fb8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_and_plot(generated, timestr, functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status, cond_dist, plotobjs=None):\n",
    "    scores=np.zeros((len(functions), len(methods), len(metrics), numinst))\n",
    "\n",
    "    #Find the highest number of objectives in any problem\n",
    "    max_obj = 0\n",
    "    if obj_status:\n",
    "        for i in range(len(functions)):\n",
    "            if len(functions[i][2])>max_obj:\n",
    "                max_obj = len(functions[i][2])\n",
    "        \n",
    "    \n",
    "    #Calculate how many plots per row we will be generating\n",
    "    plots_in_row = 1 + validity_status +(len(methods)*(1+cond_dist)+max_obj*obj_status + conditional_status+cond_dist)\n",
    "\n",
    "    #Loop over training instances\n",
    "    for inst in range(numinst):\n",
    "        #Initialize subplots\n",
    "        fig, ax = plt.subplots(len(functions), plots_in_row, figsize=(10*plots_in_row-0.2, 10*len(functions)-0.9))\n",
    "\n",
    "        #Loop over problems to test\n",
    "        for func in range(len(functions)):\n",
    "            #Unpack problem info\n",
    "            samplingfunction, validityfunction, objectives, rangearr, cond_func, cond = functions[func]\n",
    "            \n",
    "            #Generate the data\n",
    "            valid_scaled, invalid_scaled, scaler = load_data.gen_toy_dataset(samplingfunction, validityfunction, objectives, rangearr, scaling)\n",
    "\n",
    "            #Get some unscaled versions for plotting\n",
    "            if scaling: \n",
    "                valid = scaler.inverse_transform(valid_scaled)\n",
    "                try:\n",
    "                    invalid = scaler.inverse_transform(invalid_scaled)\n",
    "                except:\n",
    "                    invalid = np.array([[None,None]])\n",
    "            else:\n",
    "                valid = valid_scaled\n",
    "                invalid = invalid_scaled\n",
    "\n",
    "            #Evaluate objective values for all datapoints\n",
    "            if objectives:\n",
    "                y_valid = load_data.eval_obj(valid, objectives)\n",
    "                \n",
    "                #If rediscovery in metrics, split valid and y_valid\n",
    "                if \"Rediscovery\" in metrics:\n",
    "                    valid_scaled, vr, y_valid, yr = train_test_split(valid_scaled, y_valid, test_size=0.05, random_state=0)\n",
    "            else:\n",
    "                #If rediscovery in metrics, split valid\n",
    "                y_valid = None\n",
    "                if \"Rediscovery\" in metrics:\n",
    "                    valid_scaled, vr = train_test_split(valid_scaled, test_size=0.05, random_state=0)\n",
    "                yr = None\n",
    "                \n",
    "                    \n",
    "            xx, yy, Z = load_data.gen_background_plot(validityfunction, rangearr)\n",
    "            plot(fig.axes[plots_in_row*func], rangearr, xx, yy, Z, valid[:,0], valid[:,1], None, None, \n",
    "                 \"Original valid data\", validity_status=validity_status, plottype = \"dataset\")\n",
    "            if validity_status==1:\n",
    "                plot(fig.axes[plots_in_row*func+1], rangearr, xx, yy, Z, invalid[:,0], invalid[:,1], None, None, \n",
    "                     \"Original invalid data\", validity_status=validity_status, plottype = \"invalid\")\n",
    "            if obj_status:\n",
    "                num_objectives = len(objectives)\n",
    "                for i in range(num_objectives):\n",
    "                    xx_o, yy_o, Z_o = load_data.gen_background_plot(objectives[i], rangearr)\n",
    "                    obj_idx = plots_in_row*func+1+validity_status+i\n",
    "                    plot(fig.axes[obj_idx], rangearr, xx_o, yy_o, Z_o, valid[:,0], valid[:,1], None, None, \"Objective \" +str(i+1), \n",
    "                         plottype = \"objective\", validity_status=validity_status, target=plotobjs[i])\n",
    "            else:\n",
    "                num_objectives = 0\n",
    "            if conditional_status:\n",
    "                c_valid = load_data.eval_obj(valid, [cond_func])\n",
    "                \n",
    "                xx_o, yy_o, Z_o = load_data.gen_background_plot(cond_func, rangearr)\n",
    "                cond_idx=plots_in_row*func+1+validity_status+num_objectives*obj_status\n",
    "                plot(fig.axes[cond_idx], rangearr, xx_o, yy_o, Z_o, valid[:,0], valid[:,1], None, None, \"\", \n",
    "                         plottype = \"objective\", validity_status=validity_status, target=plotobjs[num_objectives])\n",
    "                \n",
    "            if cond_dist:\n",
    "                mask = evaluation.get_perc_band(cond, c_valid, 0.1)\n",
    "                valid_mask = valid[mask]\n",
    "                if objectives:\n",
    "                    y_valid_mask = y_valid[mask]\n",
    "                else:\n",
    "                    y_valid_mask = None\n",
    "                valid_scaled_mask = valid_scaled[mask]\n",
    "                cond_mask = c_valid[mask]\n",
    "\n",
    "                \n",
    "                \n",
    "            #Loop over methods to test\n",
    "            for i in range(len(methods)): \n",
    "                if cond_dist:\n",
    "                    plot(fig.axes[cond_idx+1], rangearr, xx, yy, Z, valid_mask[:,0], valid_mask[:,1], None, None,\n",
    "                             methods.index[i], validity_status=validity_status, plottype = \"dataset\")\n",
    "                    \n",
    "                x_fake_scaled = generated[func, i, inst, :, :]\n",
    "                \n",
    "                if scaling==True:\n",
    "                    x_fake = scaler.inverse_transform(x_fake_scaled)\n",
    "                else:\n",
    "                    x_fake = x_fake_scaled\n",
    "                    \n",
    "                if objectives:\n",
    "                    y_fake = load_data.eval_obj(x_fake, objectives)\n",
    "                else:\n",
    "                    y_fake = None\n",
    "                \n",
    "\n",
    "                for j in range(len(metrics)):\n",
    "                    if metrics.index[j]==\"Validity\":\n",
    "                        allscores, meanscore = evaluation.evaluate_validity(x_fake, validityfunction)\n",
    "                    elif metrics.index[j]==\"Rediscovery\":\n",
    "                        allscores, meanscore = metrics.values[j](x_fake_scaled, y_fake, vr, yr, invalid_scaled, scorebars)\n",
    "                    elif metrics.index[j]==\"Conditioning Reconstruction\":\n",
    "                        allscores, meanscore = metrics.values[j](x_fake_scaled, y_fake, valid_scaled, c_valid, invalid_scaled, scorebars)\n",
    "                    elif metrics.index[j]==\"Conditioning Adherence\":\n",
    "                        c_gen = load_data.eval_obj(x_fake, [cond_func])\n",
    "                        allscores=None\n",
    "                        meanscore = sklearn.metrics.mean_squared_error(c_gen, np.ones_like(c_gen)*cond)\n",
    "                    else:\n",
    "                        if cond_dist:\n",
    "                            allscores, meanscore = metrics.values[j](x_fake_scaled, y_fake, valid_scaled_mask, y_valid_mask, invalid_scaled, scorebars)\n",
    "                        else:\n",
    "                            allscores, meanscore = metrics.values[j](x_fake_scaled, y_fake, valid_scaled, y_valid, invalid_scaled, scorebars)\n",
    "                    scores[func, i, j, inst] = meanscore\n",
    "                res_idx=plots_in_row*func+1+validity_status+max_obj*obj_status+i*(1+cond_dist)+conditional_status+cond_dist\n",
    "                if validity_status:\n",
    "                    labels, _ = evaluation.evaluate_validity(x_fake, validityfunction)\n",
    "                    labels = labels.astype(bool)\n",
    "                    plot(fig.axes[res_idx], rangearr, xx, yy, Z, x_fake[:,0][labels], x_fake[:,1][labels], x_fake[:,0][~labels], x_fake[:,1][~labels], \n",
    "                         methods.index[i], plottype=\"generated\", validity_status = validity_status)                \n",
    "                else:\n",
    "                    plot(fig.axes[res_idx], rangearr, xx, yy, Z, x_fake[:,0], x_fake[:,1], valid[:,0], valid[:,1], methods.index[i], \n",
    "                         plottype=\"generated\", validity_status = validity_status)\n",
    "                if cond_dist:\n",
    "                    plot(fig.axes[res_idx+1], rangearr, xx, yy, Z, x_fake[:,0], x_fake[:,1], valid_mask[:,0], valid_mask[:,1],\n",
    "                         methods.index[i], validity_status=validity_status, plottype = \"conditional\")\n",
    "        plt.show()\n",
    "        fig.savefig(f\"Scores/{inst}_{timestr}.png\", dpi=400)\n",
    "\n",
    "    for i in range(np.shape(scores)[0]):\n",
    "        meanscores = np.mean(scores[i], axis=(2))\n",
    "        scoredf = pd.DataFrame(meanscores, index=methods.index, columns = metrics.index).transpose()\n",
    "        scoredf.columns.name=f\"Problem {i+1} Scores:\"\n",
    "        scoredf.to_csv(f\"Scores/problem_{i+1}_{timestr}.csv\", index_label=scoredf.columns.name)\n",
    "        print(scoredf)\n",
    "\n",
    "    #average scores\n",
    "\n",
    "    meanscores = np.mean(scores, axis=(0,3))\n",
    "    scoredf = pd.DataFrame(meanscores, index=methods.index, columns = metrics.index).transpose()\n",
    "    scoredf.columns.name=\"Average scores:\"\n",
    "    print(scoredf)\n",
    "    scoredf.to_csv(f\"Scores/{timestr}.csv\", index_label=scoredf.columns.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99d632",
   "metadata": {},
   "source": [
    "**General Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numgen = 1000 #Number of samples to generate\n",
    "numinst = 1 #Number of instantiations to test\n",
    "scaling = True #Scale or not\n",
    "scorebars = True #Print progress bars for scoring functions\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb84ab7",
   "metadata": {},
   "source": [
    "**Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions=[]\n",
    "\n",
    "DM_val = load_data.all_val_wrapper()\n",
    "\n",
    "#In this case, we include objectives specifically for ML efficacy\n",
    "DM_objs = [load_data.KNO1_a_wrapper(4,4), load_data.KNO1_b_wrapper(4,4)] \n",
    "\n",
    "pareto = np.stack([0.4705*np.linspace(0,1,1000), 0.4705*np.linspace(1,0,1000)], axis=1)\n",
    "sampling_func = load_data.sample_circle_blobs_wrapper(10000, 6, 1.3, 0.22) #Uniform Sampling with Number of positive samples & Negative Samples\n",
    "\n",
    "rangearr = np.array([[-2,2], [-2,2]])\n",
    "functions.append([sampling_func, DM_val, DM_objs, rangearr, None, None])\n",
    "\n",
    "reg_clf_params = None\n",
    "config_params = [False, False, False, None, None, False]\n",
    "train_params = [1, 0, 4, 5000] #Setting DPP weight to 0 for normal GAN\n",
    "DTAI_params= [None, None, None]\n",
    "\n",
    "methods=pd.Series()\n",
    "methods[\"GAN\"] = Padgan_variants.padgan_wrapper(config_params, train_params, DTAI_params, reg_clf_params, reg_clf_params)\n",
    "methods[\"VAE\"] = VAEs.VAE_wrapper([100, 128, 1e-3, 4, .05, False])\n",
    "\n",
    "metrics=pd.Series()\n",
    "metrics[\"Nearest Dataset Sample\"] = evaluation.gen_data_distance_wrapper(\"x\", \"min\")\n",
    "metrics[\"Nearest Generated Sample\"] = evaluation.data_gen_distance_wrapper(\"x\", \"min\")\n",
    "metrics[\"Rediscovery\"] = evaluation.data_gen_distance_wrapper(\"x\", \"min\")\n",
    "metrics[\"F1\"] = evaluation.F_wrapper(\"x\", 1)\n",
    "metrics[\"F10\"] = evaluation.F_wrapper(\"x\", 10)\n",
    "metrics[\"F0.1\"] = evaluation.F_wrapper(\"x\", 0.1)\n",
    "metrics[\"AUC-PR\"] = evaluation.AUC_wrapper(\"x\")\n",
    "metrics[\"MMD\"] = evaluation.MMD_wrapper()\n",
    "metrics[\"ML Efficacy\"] = evaluation.ML_efficacy_wrapper(KNeighborsRegressor(n_neighbors=5), r2_score)\n",
    "\n",
    "\n",
    "validity_status = 0 #whether we are considering constraints\n",
    "obj_status = 0 #wheteher we are considering functional perfomrance\n",
    "conditional_status = 0 #whether we are considering conditioning\n",
    "cond_dist=False #Whether conditional metrics are compared against conditional or marginal distribution\n",
    "\n",
    "generated, timestr = fit_and_generate(functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status)\n",
    "score_and_plot(generated, timestr, functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status, cond_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1199e19b",
   "metadata": {},
   "source": [
    "**Diversity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1892c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions=[]\n",
    "\n",
    "DM_val = load_data.all_val_wrapper()\n",
    "pareto = np.stack([0.4705*np.linspace(0,1,1000), 0.4705*np.linspace(1,0,1000)], axis=1)\n",
    "sampling_func = load_data.sample_circle_blobs_wrapper(10000, 6, 1.3, 0.22) #Uniform Sampling with Number of positive samples & Negative Samples\n",
    "\n",
    "rangearr = np.array([[-2,2], [-2,2]])\n",
    "functions.append([sampling_func, DM_val, None, rangearr, None, None])\n",
    "\n",
    "reg_clf_params = None\n",
    "config_params = [False, False, False, None, None, False]\n",
    "train_params = [1, 0, 4, 5000] #Setting DPP weight to 0 for normal GAN\n",
    "DTAI_params= [None, None, None]\n",
    "\n",
    "methods=pd.Series()\n",
    "methods[\"GAN\"] = Padgan_variants.padgan_wrapper(config_params, train_params, DTAI_params, reg_clf_params, reg_clf_params)\n",
    "methods[\"VAE\"] = VAEs.VAE_wrapper([100, 128, 1e-3, 4, .05, False])\n",
    "\n",
    "\n",
    "metrics=pd.Series()\n",
    "metrics[\"Inter-Generated Sample\"] = evaluation.gen_gen_distance_wrapper(\"x\", \"min\")\n",
    "metrics[\"Convex Hull\"] = evaluation.convex_hull_wrapper(\"x\")\n",
    "metrics[\"DPP Diversity\"] = evaluation.DPP_diversity_wrapper(\"x\")\n",
    "metrics[\"Nearest Generated Sample\"] = evaluation.data_gen_distance_wrapper(\"x\", \"min\")\n",
    "metrics[\"Distance to Centroid\"] = evaluation.distance_to_centroid_wrapper(\"x\")\n",
    "\n",
    "\n",
    "validity_status = 0 #whether we are considering constraints\n",
    "obj_status = 0 #wheteher we are considering functional perfomrance\n",
    "conditional_status = 0 #whether we are considering conditioning\n",
    "cond_dist=False #Whether conditional metrics are compared against conditional or marginal distribution\n",
    "\n",
    "generated, timestr = fit_and_generate(functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status)\n",
    "score_and_plot(generated, timestr, functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status, cond_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a3b0bc",
   "metadata": {},
   "source": [
    "**Constraint Adherence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93767f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions=[]\n",
    "\n",
    "sampling_func_2 = load_data.sample_uniform_wrapper(10000, 10000) #Uniform Sampling with Number of positive samples & Negative Samples\n",
    "validity_func_2 = load_data.concentric_circles_val_wrapper(2)\n",
    "rangearr_2 = np.array([[-1,1], [-1,1]])\n",
    "functions.append([sampling_func_2, validity_func_2, None, rangearr_2, None, None])\n",
    "\n",
    "reg_clf_params = None\n",
    "config_params = [False, False, False, None, None, False]\n",
    "train_params = [1, 0, 4, 5000] #Setting DPP weight to 0 for normal GAN\n",
    "DTAI_params= [None, None, None]\n",
    "\n",
    "methods=pd.Series()\n",
    "methods[\"GAN\"] = Padgan_variants.padgan_wrapper(config_params, train_params, DTAI_params, reg_clf_params, reg_clf_params)\n",
    "methods[\"VAE\"] = VAEs.VAE_wrapper([100, 128, 1e-3, 4, .05, False])\n",
    "\n",
    "\n",
    "metrics=pd.Series()\n",
    "metrics[\"Predicted Constraint Satisfaction\"] = evaluation.predicted_constraint_satisfaction_wrapper(KNeighborsClassifier(n_neighbors=5))\n",
    "metrics[\"Validity\"] = None\n",
    "metrics[\"Nearest Invalid Sample\"] = evaluation.gen_neg_distance_wrapper(\"min\")\n",
    "\n",
    "\n",
    "validity_status = 1 #whether we are considering constraints\n",
    "obj_status = 0 #wheteher we are considering functional perfomrance\n",
    "conditional_status = 0 #whether we are considering conditioning\n",
    "cond_dist=False #Whether conditional metrics are compared against conditional or marginal distribution\n",
    "\n",
    "generated, timestr = fit_and_generate(functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status)\n",
    "score_and_plot(generated, timestr, functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status, cond_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fbccec",
   "metadata": {},
   "source": [
    "**Performance and Target Achievement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac932eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions=[]\n",
    "\n",
    "Perf_val = load_data.all_val_wrapper()\n",
    "pareto = np.stack([0.4705*np.linspace(0,1,1000), 0.4705*np.linspace(1,0,1000)], axis=1)\n",
    "sampling_func = load_data.sample_circle_blobs_wrapper(10000, 6, 1.3, 0.22) #Uniform Sampling with Number of positive samples & Negative Samples\n",
    "Perf_objs = [load_data.KNO1_a_wrapper(4,4), load_data.KNO1_b_wrapper(4,4)] \n",
    "rangearr = np.array([[-2,2], [-2,2]])\n",
    "functions.append([sampling_func, Perf_val, Perf_objs, rangearr, None, None])\n",
    "\n",
    "reg_clf_params = None\n",
    "config_params = [False, False, False, None, None, False]\n",
    "train_params = [1, 0, 4, 5000] #Setting DPP weight to 0 for normal GAN\n",
    "DTAI_params= [None, None, None]\n",
    "\n",
    "methods=pd.Series()\n",
    "methods[\"GAN\"] = Padgan_variants.padgan_wrapper(config_params, train_params, DTAI_params, reg_clf_params, reg_clf_params)\n",
    "\n",
    "# Regressor/Classifier params: [dropout, layers, layersize, batchnorm, activation, patience, lr, batchsize, epochs]\n",
    "reg_clf_params = [0.1, 2, 100, True, \"Leaky ReLU\", 30, 1e-4, 32, 100]\n",
    "config_params = [False, False, False, \"auto\", \"auto\", False]\n",
    "train_params = [5, 2, 4, 5000]\n",
    "DTAI_params= [\"auto\", \"auto\", \"auto\"]\n",
    "methods[\"MO-PaDGAN\"] = Padgan_variants.padgan_wrapper(config_params, train_params, DTAI_params, reg_clf_params, reg_clf_params)\n",
    "\n",
    "metrics=pd.Series()\n",
    "target = np.array([0.5, 0.5])\n",
    "a_ = np.array([1, 1])\n",
    "p_ = np.array([1, 1])\n",
    "direction = \"maximize\"\n",
    "metrics[\"Minimum Target Ratio\"] = evaluation.minimum_target_ratio_wrapper(direction, target)\n",
    "metrics[\"DTAI\"] = evaluation.DTAI_wrapper(direction, target, a_, p_)\n",
    "metrics[\"Hypervolume\"] = evaluation.Hypervolume_wrapper()\n",
    "metrics[\"Generational Distance\"] = evaluation.Generational_distance_wrapper(pareto)\n",
    "metrics[\"Weighted Target Success Rate\"] = evaluation.weighted_target_success_rate_wrapper(direction, target, p_)\n",
    "metrics[\"Signed Distance to Target\"] = evaluation.signed_distance_to_boundary_wrapper(direction, target, a_)\n",
    "\n",
    "\n",
    "validity_status = 0 #whether we are considering constraints\n",
    "obj_status = 1 #wheteher we are considering functional perfomrance\n",
    "conditional_status = 0 #whether we are considering conditioning\n",
    "cond_dist=False #Whether conditional metrics are compared against conditional or marginal distribution\n",
    "plotobjs = target\n",
    "\n",
    "generated, timestr = fit_and_generate(functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status)\n",
    "score_and_plot(generated, timestr, functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status, cond_dist, plotobjs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef0c8ff",
   "metadata": {},
   "source": [
    "**Conditioning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53120af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Note: only continuous conditioning is currently supported\n",
    "\n",
    "importlib.reload(load_data)\n",
    "# importlib.reload(GANs)\n",
    "importlib.reload(VAEs)\n",
    "\n",
    "functions=[]\n",
    "\n",
    "DM_val = load_data.all_val_wrapper()\n",
    "pareto = np.stack([0.4705*np.linspace(0,1,1000), 0.4705*np.linspace(1,0,1000)], axis=1)\n",
    "sampling_func = load_data.sample_circle_blobs_wrapper(10000, 6, 1.3, 0.22) #Uniform Sampling with Number of positive samples & Negative Samples\n",
    "rangearr = np.array([[-2,2], [-2,2]])\n",
    "cond_func = load_data.exp_obj_wrapper(1,1)\n",
    "cond=0.3\n",
    "functions.append([sampling_func, DM_val, None, rangearr, cond_func, cond])\n",
    "\n",
    "\n",
    "reg_clf_params = None\n",
    "config_params_cond = [False, False, False, None, None, True]\n",
    "train_params = [1, 0, 4, 5000] #Setting DPP weight to 0 for normal GAN\n",
    "DTAI_params= [None, None, None]\n",
    "\n",
    "methods=pd.Series()\n",
    "methods[\"cGAN\"] = Padgan_variants.padgan_wrapper(config_params_cond, train_params, DTAI_params, reg_clf_params, reg_clf_params)\n",
    "methods[\"cVAE\"] = VAEs.VAE_wrapper([100, 128, 1e-3, 4, .05, True])\n",
    "\n",
    "metrics=pd.Series()\n",
    "metrics[\"Nearest Dataset Sample\"] = evaluation.gen_data_distance_wrapper(\"x\", \"min\")\n",
    "metrics[\"Nearest Generated Sample\"] = evaluation.data_gen_distance_wrapper(\"x\", \"min\")\n",
    "metrics[\"F1\"] = evaluation.F_wrapper(\"x\", 1)\n",
    "metrics[\"F10\"] = evaluation.F_wrapper(\"x\", 10)\n",
    "metrics[\"F0.1\"] = evaluation.F_wrapper(\"x\", 0.1)\n",
    "metrics[\"AUC-PR\"] = evaluation.AUC_wrapper(\"x\")\n",
    "metrics[\"MMD\"] = evaluation.MMD_wrapper()\n",
    "\n",
    "metrics[\"Conditioning Reconstruction\"] = evaluation.predicted_conditioning_wrapper(KNeighborsRegressor(n_neighbors=5), cond)\n",
    "metrics[\"Conditioning Adherence\"] = None\n",
    "\n",
    "validity_status = 0 #whether we are considering constraints\n",
    "obj_status = 0 #wheteher we are considering functional perfomrance\n",
    "conditional_status = 1 #whether we are considering conditioning\n",
    "cond_dist=True #Whether conditional metrics are compared against conditional or marginal distribution\n",
    "\n",
    "\n",
    "#Generate a new set of results\n",
    "generated, timestr = fit_and_generate(functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status)\n",
    "plotobjs = [cond]\n",
    "#OR Load a set of results from a timestring:\n",
    "# timestr= \"20230204-161902\"\n",
    "# generated = np.load(f\"Scores/Generated_samples_{timestr}.npy\")\n",
    "\n",
    "score_and_plot(generated, timestr, functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status, cond_dist, plotobjs)\n",
    "# score_and_plot(generated, timestr, functions, methods, numinst, numgen, scaling, validity_status, obj_status, conditional_status, False, plotobjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3af6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c018740c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
