{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19909396",
   "metadata": {},
   "source": [
    "**Using Evaluation Utils**:\n",
    "\n",
    "In this notebook, we discuss how to use the provided utilities file to compare models on numerous metrics on different problems at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb20ba3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyle\\Documents\\DeCoDE\\DGM-Evaluation-Metrics\\Padgan_variants.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import evaluation\n",
    "import load_data\n",
    "import Padgan_variants\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import Padgan_variants\n",
    "import VAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45e115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9599e141",
   "metadata": {},
   "source": [
    "**Setting up DGMS**:\n",
    "\n",
    "Let's create a pandas series with several DGMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6acf9802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyle\\AppData\\Local\\Temp\\ipykernel_21900\\4055154814.py:6: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  methods=pd.Series()\n"
     ]
    }
   ],
   "source": [
    "reg_clf_params = None\n",
    "config_params = [False, False, False, None, None, False]\n",
    "train_params = [1, 0, 4, 5] #Setting DPP weight to 0 for normal GAN\n",
    "DTAI_params= [None, None, None]\n",
    "\n",
    "methods=pd.Series()\n",
    "methods[\"GAN\"] = Padgan_variants.padgan_wrapper(config_params, train_params, DTAI_params, reg_clf_params, reg_clf_params)\n",
    "methods[\"VAE\"] = VAEs.VAE_wrapper([1, 128, 1e-3, 4, .05, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8896a90b",
   "metadata": {},
   "source": [
    "**Setting up Problems**\n",
    "\n",
    "The utilities provided expect each function to be specified as a list of the following components:\n",
    "- Sampling function\n",
    "- Validity test\n",
    "- Objectives\n",
    "- Plotting Range\n",
    "- Conditioning Function \n",
    "- Condition Value\n",
    "\n",
    "Unused components can be left as None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a53367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions=[]\n",
    "\n",
    "DM_val = load_data.all_val_wrapper()\n",
    "\n",
    "pareto = np.stack([0.4705*np.linspace(0,1,1000), 0.4705*np.linspace(1,0,1000)], axis=1)\n",
    "sampling_func_1 = load_data.sample_circle_blobs_wrapper(10000, 6, 1.3, 0.22) #Uniform Sampling with Number of positive samples & Negative Samples\n",
    "sampling_func_2 = load_data.sample_circle_blobs_wrapper(10000, 2, 1.3, 0.22) #Uniform Sampling with Number of positive samples & Negative Samples\n",
    "\n",
    "rangearr = np.array([[-2,2], [-2,2]])\n",
    "\n",
    "functions.append([sampling_func_1, DM_val, None, rangearr, None, None])\n",
    "functions.append([sampling_func_2, DM_val, None, rangearr, None, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f7cd8f",
   "metadata": {},
   "source": [
    "**Setting Up Metrics**:\n",
    "We set up teh metrics we want to evaluate in a pandas series. \n",
    "Each entry consists of:\n",
    "metrics[\"name\"] = [\"direction\", metric wrapper]\n",
    "\n",
    "- name is a name you are assigning to the metrics\n",
    "- direction is either \"minimize\" or \"maximize\"\n",
    "- metric wrapper is the a wrapper function of the desired metric with any hyperparameters specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16657093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyle\\AppData\\Local\\Temp\\ipykernel_21900\\2384849321.py:1: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  metrics=pd.Series()\n"
     ]
    }
   ],
   "source": [
    "metrics=pd.Series()\n",
    "metrics[\"Nearest Dataset Sample\"] = [\"minimize\", evaluation.gen_data_distance_wrapper(\"x\", \"min\")]\n",
    "metrics[\"Nearest Generated Sample\"] = [\"minimize\", evaluation.data_gen_distance_wrapper(\"x\", \"min\")]\n",
    "metrics[\"F1\"] = [\"maximize\", evaluation.F_wrapper(\"x\", 1)]\n",
    "metrics[\"F10\"] = [\"maximize\", evaluation.F_wrapper(\"x\", 10)]\n",
    "metrics[\"F0.1\"] = [\"maximize\", evaluation.F_wrapper(\"x\", 0.1)]\n",
    "metrics[\"AUC-PR\"] = [\"maximize\", evaluation.AUC_wrapper(\"x\")]\n",
    "metrics[\"MMD\"] = [\"minimize\", evaluation.MMD_wrapper()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad861b",
   "metadata": {},
   "source": [
    "**General Parameters**\n",
    "\n",
    "We set up some flags and general settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ff377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numgen = 1000 #Number of samples to generate\n",
    "numinst = 3 #Number of instantiations to test\n",
    "scaling = True #Scale or not\n",
    "scorebars = True #Print progress bars for scoring functions\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "validity_status = 0 #whether we are considering constraints\n",
    "obj_status = 0 #whether we are considering functional performance\n",
    "conditional_status = 0 #whether we are considering conditioning\n",
    "cond_dist=False #Whether conditional metrics are compared against conditional or marginal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f733a2",
   "metadata": {},
   "source": [
    "**fit_and_generate**\n",
    "We call fit_and_generate from the utilities file to generate the datasets and train the models. \n",
    "fit_and_generate takes:\n",
    "- functions: Our list of functions defined earlier\n",
    "- methods: Our list of methods defined earlier\n",
    "- numinst: How many model instantiations to test\n",
    "- numgen: How many points to sample from each generated model\n",
    "- scaling: Whether to scale the datasets before training\n",
    "- obj_status: #wheteher we are considering functional performance\n",
    "- conditional_status: Whether we are considering conditioning\n",
    "- holdout: fraction of dataset to hold out during training (used for rediscovery)\n",
    "\n",
    "The fit_and_generate function returns a timestamp in a string corresponding to the folder in which the results are saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b53ac53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Lambda1 set to 0, DPP loss disabled; Ignoring CLF and REG...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fda01a9891b44c1ad0c0a6b238692ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Training::   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 11ms/step - loss: 0.7225 - reconstruction_loss: 0.3518 - kl_loss: 2.3559\n",
      "0\n",
      "Lambda1 set to 0, DPP loss disabled; Ignoring CLF and REG...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fd79b67cbd4c93aad88364994014e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Training::   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 13ms/step - loss: 0.7321 - reconstruction_loss: 0.3747 - kl_loss: 2.2549\n",
      "0\n",
      "Lambda1 set to 0, DPP loss disabled; Ignoring CLF and REG...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a7d5677ca64dfb89bceaded8fc5226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Training::   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 13ms/step - loss: 0.7052 - reconstruction_loss: 0.3401 - kl_loss: 2.4996\n",
      "0\n",
      "Lambda1 set to 0, DPP loss disabled; Ignoring CLF and REG...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5ec60ea5e34a60913d3d1177bdaed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Training::   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 13ms/step - loss: 0.7277 - reconstruction_loss: 0.3471 - kl_loss: 2.2950\n",
      "0\n",
      "Lambda1 set to 0, DPP loss disabled; Ignoring CLF and REG...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc975a05fce4dddaf4b376c603782bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Training::   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 13ms/step - loss: 0.7353 - reconstruction_loss: 0.3631 - kl_loss: 2.1943\n",
      "0\n",
      "Lambda1 set to 0, DPP loss disabled; Ignoring CLF and REG...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a16aa3cf2134fc5be3d7f01af188322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Training::   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 12ms/step - loss: 0.7603 - reconstruction_loss: 0.4106 - kl_loss: 2.1893\n"
     ]
    }
   ],
   "source": [
    "timestr = utils.fit_and_generate(functions, methods, numinst, numgen, scaling, obj_status, conditional_status, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbeb5f8",
   "metadata": {},
   "source": [
    "**score**:\n",
    "Next, we score the generated models. The scroring utilities function takes:\n",
    "- timestr: the timestring corresponding to the results we want to evaluate\n",
    "- functions: Our list of functions defined earlier\n",
    "- methods: Our list of methods defined earlier\n",
    "- metrics: The metrics to test\n",
    "- numinst: How many model instantiations to test\n",
    "- scaling: Whether to scale the datasets before training \n",
    "- cond_dist: Whether conditional metrics are compared against conditional or marginal distribution\n",
    "- scorebars: Whether to print progress bars/ evaluation status\n",
    "\n",
    "score saves scores in the folder indicated by timestr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "796bd6b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:05<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:05<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:05<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n",
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n",
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n",
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n",
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:05<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:05<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n",
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n",
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n",
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n",
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:05<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:05<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n",
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n",
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n",
      "Calculating Gen-Data Distance\n",
      "Calculating Data-Gen Distance\n",
      "Calculating F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:07<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision/Recall:: 100%|===================================================| 10/10 [00:08<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Maximum Mean Discrepancy\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnuminst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorebars\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\DeCoDE\\DGM-Evaluation-Metrics\\utils.py:401\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(timestr, functions, methods, metrics, numinst, scaling, cond_dist, scorebars, plotobjs, style)\u001b[0m\n\u001b[0;32m    399\u001b[0m     scoredf \u001b[38;5;241m=\u001b[39m highlight_best(scoredf, scoredf_raw, [v[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mvalues])\n\u001b[0;32m    400\u001b[0m scoredf\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProblem \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Scores:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 401\u001b[0m \u001b[43mscoredf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResults/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtimestr\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/Scores/problem_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_scores.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoredf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m style:\n\u001b[0;32m    403\u001b[0m     scoredf\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Scores/problem_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_scores.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_label\u001b[38;5;241m=\u001b[39mscoredf\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\formats\\style.py:480\u001b[0m, in \u001b[0;36mStyler.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m    469\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    471\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    478\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m    479\u001b[0m )\n\u001b[1;32m--> 480\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\formats\\excel.py:888\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    884\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 888\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:49\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     38\u001b[0m     path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m ):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# Use the openpyxl module as the Excel writer.\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     51\u001b[0m     engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     54\u001b[0m         path,\n\u001b[0;32m     55\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m     59\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "utils.score(timestr, functions, methods, metrics, numinst, scaling, cond_dist, scorebars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602dc6dc",
   "metadata": {},
   "source": [
    "**plot_all**:\n",
    "Next, we plot the generated distributions. The plotting function takes:\n",
    "\n",
    "- timestr: the timestring corresponding to the results we want to evaluate\n",
    "- functions: Our list of functions defined earlier\n",
    "- methods: Our list of methods defined earlier\n",
    "- numinst: How many model instantiations to test\n",
    "- scaling: Whether to scale the datasets before training \n",
    "- validity_status:whether we are considering constraints\n",
    "- obj_status: whether we are considering functional performance\n",
    "- conditional_status: whether we are considering conditioning\n",
    "- cond_dist: Whether conditional metrics are compared against conditional or marginal distribution\n",
    "\n",
    "plot saves plots in the folder indicated by timestr. If numinst is greater than 1, saves an animation of the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c79796",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_all(timestr, functions, methods, numinst, scaling, validity_status, obj_status, conditional_status, cond_dist, \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b9aaae",
   "metadata": {},
   "source": [
    "**Special Metrics**\n",
    "\n",
    "When working with a few special types of metrics we must do some special setup. For rediscovery, we must designate a holdout fraction which we pass to fit_and_generate. For ML efficacy, we must include an auxiliary predictive task. In this case, we encode this predictive task in an objective function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"Rediscovery\"] = [\"minimize\", evaluation.data_gen_distance_wrapper(\"x\", \"min\")]\n",
    "holdout = 0.05 #If using rediscovery, we need to hold out a portion of the data during training\n",
    "\n",
    "metrics[\"ML Efficacy\"] = [\"maximize\", evaluation.ML_efficacy_wrapper(KNeighborsRegressor(n_neighbors=5), r2_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions=[]\n",
    "\n",
    "DM_val = load_data.all_val_wrapper()\n",
    "\n",
    "#In this case, we include objectives specifically for ML efficacy\n",
    "DM_objs = [load_data.KNO1_a_wrapper(4,4), load_data.KNO1_b_wrapper(4,4)] \n",
    "\n",
    "pareto = np.stack([0.4705*np.linspace(0,1,1000), 0.4705*np.linspace(1,0,1000)], axis=1)\n",
    "sampling_func_1 = load_data.sample_circle_blobs_wrapper(10000, 6, 1.3, 0.22) #Uniform Sampling with Number of positive samples & Negative Samples\n",
    "sampling_func_2 = load_data.sample_circle_blobs_wrapper(10000, 2, 1.3, 0.22) #Uniform Sampling with Number of positive samples & Negative Samples\n",
    "\n",
    "rangearr = np.array([[-2,2], [-2,2]])\n",
    "\n",
    "functions.append([sampling_func, DM_val, DM_objs, rangearr, None, None])\n",
    "functions.append([sampling_func, DM_val, DM_objs, rangearr, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = utils.fit_and_generate(functions, methods, numinst, numgen, scaling, obj_status, conditional_status, holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b5b8dc",
   "metadata": {},
   "source": [
    "**Other Use Cases**\n",
    "\n",
    "In this notebook, we have demonstrated how to evaluate numerous models on numerous problems in a distribution-matching setting. To evaluate models for other types of problems, such as diversity, constraint satisfaction, performance, and conditioning, please refer to Notebook 3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
